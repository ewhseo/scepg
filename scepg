#!/usr/bin/env python3
# -*- coding: utf-8 -*-

###Library Config
__USE_BS = True
__USE_LXML = True
__DEBUG = True

###Import(static)
import sys
import os
import argparse
import configparser
import socket
import time
import datetime
import urllib.request
import re
import json
import html
from subprocess import call
###Import(dynamic)
#Check BeautifulSoup
if __USE_BS:
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        __USE_BS = False
#Check lxml
if __USE_LXML:
    try:
        from lxml import etree
        import lxml.builder    
    except ImportError:
        __USE_LXML = False
if not __USE_LXML:
    import xml.etree.ElementTree as ET
    from xml.dom import minidom

###Global Constant
CONFIG_FILE = "tvchannel.conf"
LIST_FILE = "tvchannel.list"

___START_TIME = time.time()


def progressLog(progress, totalCount):
    totalLength = 10
    progressLength = int((progress / totalCount) * totalLength)

    printLog(" => Progress : [%s%s] (%d/%d)" % ("#" * progressLength, "-" * (totalLength - progressLength), progress, totalCount), end = "\r", flush = True)

    if progress >= totalCount:
        printLog("")

def progressCount(progress):
    printLog(" => Count : %d" % progress, end = "\r", flush = True)

def printLog(log, end = "\n", flush = False, error = False, file = None):
    if file is None:
        out = None
        if args.v or error:
            out = sys.stderr
        else:
            out = sys.stdout

        out.write("%s%s" % (log, end))
        if flush:
            out.flush()
    else:
        for out in file:
            out.write("%s%s" % (log, end))
            if flush:
                out.flush()

def readConfig():
    global channel_list
    global retrieve_days
    global output_xml
    global output_xml_pretty_print
    global output_socket
    global post_proc
    global post_proc_args

    printLog("==> Read config file")
    progressLog(0, 4)

    config = configparser.RawConfigParser()
    config.optionxform = str
    config.read(CONFIG_FILE)

    if not config.has_section("channel_list"):
        sys.stdout.write("\n")
        printLog(" => Config file not contains channel_list section")
        exit(1)

    progressLog(1, 4)

    try:
        channel_list = config.items("channel_list")
    except configparser.Error:
        sys.stdout.write("\n")
        printLog(" => Config file not contains channel_list section")
        exit(1)

    progressLog(2, 4)

    retrieve_days = config.getint("defaults", "retrieve_days", fallback=1)
    output_xml = config.get("defaults", "output_xml", fallback="")
    output_xml_pretty_print = config.getboolean("defaults", "output_xml_pretty_print", fallback=False)
    output_socket = config.get("defaults", "output_socket", fallback="")
    post_proc = config.get("defaults", "post_proc", fallback="")
    post_proc_args = config.get("defaults", "post_proc_args", fallback="")

    progressLog(3, 4)

    if args.b:
        output_xml_pretty_print = True

    if not args.v and output_xml == "" and output_socket == "":
        printLog("")
        printLog("-v 또는 output_xml, output_socket 값이 설정되지 않았습니다.")
        exit(1)

    progressLog(4, 4)

    printLog("==> Done.", end = "\n\n")

def printXml():
    printLog("===> Print XML")

    if __USE_LXML:
        print(etree.tostring(xml, pretty_print = output_xml_pretty_print, xml_declaration = True, encoding = "UTF-8", doctype = "<!DOCTYPE tv SYSTEM \"xmltv.dtd\">").decode("utf-8"))
    else:
        if output_xml_pretty_print == True:
            print(minidom.parseString(ET.tostring(xml, encoding = "utf-8", method = "xml")).toprettyxml(indent = " "))
        else:
            print(ET.tostring(xml, encoding = "utf-8", method = "xml").decode("utf-8"))

    printLog("===> Done.", end = "\n\n")

def writeXml():
    xml_list = output_xml.split(" ")
    socket_list = output_socket.split(" ")
    if not xml_list and not socket_list:
        return

    printLog("===> Write XML")
    progress = 0
    progressLog(progress, len(xml_list) + len(socket_list))

    for xml_config in xml_list:
        f = None
        try:
            f = open(xml_config, "w")
            if __USE_LXML:
                f.writelines(etree.tostring(xml, pretty_print = output_xml_pretty_print, xml_declaration = True, encoding = "UTF-8", doctype = "<!DOCTYPE tv SYSTEM \"xmltv.dtd\">").decode("utf-8"))
            else:
                if output_xml_pretty_print:
                    print(1, output_xml_pretty_print)
                    f.writelines(minidom.parseString(ET.tostring(xml, encoding = "utf-8", method = "xml")).toprettyxml(indent = " "))
                else:
                    print(2, output_xml_pretty_print)
                    f.writelines(ET.tostring(xml, encoding = "utf-8", method = "xml").decode("utf-8"))
        except PermissionError:
            printLog(" => Permission denied : %s" % xml_config, error = True)
        except Exception as e:
            printLog(" => Unknown error : %s (%s)" % (xml_config, e.args[0]), error = True)

        if f is not None:
            f.close()

        progress += 1
        progressLog(progress, len(xml_list) + len(socket_list))

    for socket_config in socket_list:
        match_tcp = re.match("tcp:(.*):(.*)", socket_config)
        xml_socket = None
        connect = False
        if match_tcp:
            xml_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            try:
                xml_socket.connect((match_tcp.group(1), int(match_tcp.group(2))))
            except ConnectionRefusedError:
                printLog(" => Connection refuesed error : %s" % socket_config, error = True)
            except socket.gaierror:
                printLog(" => Name or service not known : %s" % socket_config, error = True)
            except Exception as e:
                printLog(" => Unknown error : %s (%s)" % (socket_config, e.args[0]), error = True)
            else:
                connect = True
        else:
            xml_socket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
            try:
                xml_socket.connect(socket_config)
            except FileNotFoundError:
                printLog(" => File not found error : %s" % socket_config, error = True)
            except PermissionError:
                printLog(" => Permission denied : %s" % socket_config, error = True)
            except Exception as e:
                printLog(" => Unknown error : %s (%s)" % (socket_config, e.args[0]), error = True)
            else:
                connect = True

        if connect:
            if __USE_LXML:
                xml_socket.send(etree.tostring(xml, pretty_print = False, xml_declaration = True, encoding = "UTF-8", doctype = "<!DOCTYPE tv SYSTEM \"xmltv.dtd\">"))
            else:
                xml_socket.send(ET.tostring(xml, encoding = "utf-8", method = "xml"))

        if xml_socket is not None:
            xml_socket.close()

        progress += 1
        progressLog(progress, len(xml_list) + len(socket_list))

    printLog("===> Done.", end = "\n\n")

def generateXmlRoot():
    global xml

    printLog("==> Genreate XML Root")

    progressLog(0, 1)

    if __USE_LXML:
        xml = lxml.builder.ElementMaker().tv()
        xml.set("source-info-name", "forumi0721.ddns.net")
        xml.set("generator-info-name", "forumi0721")
        xml.set("generator-info-url", "mailto:forumi0721@gmail.com")
    else:
        xml = ET.Element("tv", {"source-info-name":"forumi0721.ddns.net", "generator-info-name":"forumi0721", "generator-info-url":"mailto:forumi0721@gmail.com"})

    progressLog(1, 1)

    printLog("==> Done.", end = "\n\n")

def generateXmlChannel():
    printLog("==> Generate XML Channels")

    progress = 0;
    progressLog(0, len(channel_list))

    for channel_config in channel_list:
        channel = channel_config[0].split(",")

        channel_id = channel[0]
        channel_name = channel[1]

        if __USE_LXML:
            xml_channel = etree.Element("channel", id = "I%s.forumi0721.ddns.net" % channel_id)
            xml.append(xml_channel)
            
            xml_display_name1 = etree.Element("display-name")
            xml_display_name1.text = "%s %s" % (channel_id, channel_name)
            xml_channel.append(xml_display_name1)
            
            xml_display_name2 = etree.Element("display-name")
            xml_display_name2.text = channel_id 
            xml_channel.append(xml_display_name2)
            
            xml_display_name2 = etree.Element("display-name")
            xml_display_name2.text = channel_name
            xml_channel.append(xml_display_name2)
        else:
            se_channel = ET.SubElement(xml, "channel", {"id":"I%s.forumi0721.ddns.net" % channel_id})

            se_channel_1 = ET.SubElement(se_channel, "display-name")
            se_channel_1.text = "%s %s" % (channel_id, channel_name)

            se_channel_2 = ET.SubElement(se_channel, "display-name")
            se_channel_2.text = channel_id

            se_channel_3 = ET.SubElement(se_channel, "display-name")
            se_channel_3.text = channel_name

        progress += 1
        progressLog(progress, len(channel_list))

    printLog("==> Done.", end = "\n\n")

def generateXmlProgramme(dic_programme):
    if __USE_LXML:
        xml_programme = etree.Element("programme", channel = "I%s.forumi0721.ddns.net" % dic_programme["channel_id"], channel_name = dic_programme["channel_name"], channel_no = dic_programme["channel_id"], start = "%s +0900" % dic_programme["programme_start"], stop = "%s +0900" % dic_programme["programme_stop"])
        xml.append(xml_programme)

        xml_title = etree.Element("title", lang = "ko" )
        xml_title.text = dic_programme["title"]
        xml_programme.append(xml_title)

        xml_sub_title = etree.Element("sub-title", lang = "ko" )
        if "sub_title" in dic_programme:
            xml_sub_title.text = dic_programme["sub_title"]
        else:
            xml_sub_title.text = dic_programme["title"]
        xml_programme.append(xml_sub_title)

        xml_desc = etree.Element("desc", lang = "ko" )
        if "desc" in dic_programme:
            xml_desc.text = dic_programme["desc"]
        else:
            xml_desc.text = dic_programme["title"]
        xml_programme.append(xml_desc)

        if "episode_num" in dic_programme:
            xml_episode_num = etree.Element("episode-num", system = "onscreen" )
            xml_episode_num.text = dic_programme["episode_num"]
            xml_programme.append(xml_episode_num)

        category = getCategory(dic_programme["category"])
        if category[0] != "":
            xml_category_ko = etree.Element("category", lang = "ko" )
            xml_category_ko.text = category[0]
            xml_programme.append(xml_category_ko)

        if category[1] != "":
            xml_category_en = etree.Element("category", lang = "en" )
            xml_category_en.text = category[1]
            xml_programme.append(xml_category_en)

        xml_language = etree.Element("language")
        xml_language.text = "ko"
        xml_programme.append(xml_language)

        if "rating" in dic_programme:
            xml_rating = etree.Element("rating", system = "VCHIP")
            xml_programme.append(xml_rating)
            xml_rating_value = etree.Element("value")
            xml_rating_value.text = dic_programme["rating"]
            xml_rating.append(xml_rating_value)

        xml_generate_source = etree.Element("generate-source", name = dic_programme["generate_source"])
        xml_programme.append(xml_generate_source)
    else:
        se_programme = ET.SubElement(xml, "programme", {"start":"%s +0900" % dic_programme["programme_start"], "stop":"%s +0900" % dic_programme["programme_stop"], "channel":"I%s.forumi0721.ddns.net" % dic_programme["channel_id"], "channel_no":dic_programme["channel_id"], "channel_name":dic_programme["channel_name"]})

        se_title = ET.SubElement(se_programme, "title", {"lang":"ko"})
        se_title.text = dic_programme["title"]

        se_sub_title = ET.SubElement(se_programme, "sub-title", {"lang":"ko"})
        if "sub_title" in dic_programme:
            se_sub_title.text = dic_programme["sub_title"]
        else:
            se_sub_title.text = dic_programme["title"]

        se_desc = ET.SubElement(se_programme, "desc", {"lang":"ko"})
        if "desc" in dic_programme:
            se_desc.text = dic_programme["desc"]
        else:
            se_desc.text = dic_programme["title"]

        if "episode_num" in dic_programme:
            se_episode_num = ET.SubElement(se_programme, "episode-num", {"system":"onscreen"})
            se_episode_num.text = dic_programme["episode_num"]

        category = getCategory(dic_programme["category"])
        if category[0] != "":
            se_category_ko = ET.SubElement(se_programme, "category", {"lang":"ko"})
            se_category_ko.text = category[0]

        if category[1] != "":
            se_category_en = ET.SubElement(se_programme, "category", {"lang":"en"})
            se_category_en.text = category[1]

        se_language = ET.SubElement(se_programme, "language")
        se_language.text = "ko"

        if "rating" in dic_programme:
            se_rating = ET.SubElement(se_programme, "rating", {"system":"VCHIP"})
            se_rating_value = ET.SubElement(se_rating, "value")
            se_rating_value.text = dic_programme["rating"]

        se_generate_source = ET.SubElement(se_programme, "generate-source", {"name":dic_programme["generate_source"]})

def generateXmlProgrammeUplus():
    channel_config = [[k, v] for k, v in channel_list if v[0] == "U"]
    if len(channel_config) <= 0:
        return

    generate_source = "http://www.uplus.co.kr/"
    base_url = "http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvSchedule.hpi?chnlCd={channel_code}&evntCmpYmd={date_ymd}"

    printLog("===> Generate Programmes (Uplus)")
    progress = 0
    progressLog(0, len(channel_config) * retrieve_days)

    for channel in channel_config:
        channel_id = channel[0].split(",")[0]
        channel_name = channel[0].split(",")[1]
        channel_code = channel[1].split(",")[1]

        dic_programme = {}

        for day in range(retrieve_days):
            download_date = (datetime.date.today() + datetime.timedelta(days = day))
            url = base_url.replace("{channel_code}", channel_code).replace("{date_ymd}", download_date.strftime("%Y%m%d"))

            with urllib.request.urlopen(url) as f:
                body = f.read().decode("cp949", "ignore").partition("<tbody>")[2].rpartition("</tbody>")[0]
                if __USE_BS:
                    if __USE_LXML:
                        soup = BeautifulSoup(body, "lxml")
                    else:
                        soup = BeautifulSoup(body, "html.parser")
                    for tr in soup.find_all("tr"):
                        row = 0
                        for td in tr.find_all("td"):
                            if row == 0:
                                if dic_programme:
                                    dic_programme["programme_stop"] = "%s%s" % (download_date.strftime("%Y%m%d"), str(td.next_element).strip().replace(":", ""))
                                    generateXmlProgramme(dic_programme)

                                dic_programme.clear()
                                dic_programme["channel_id"] = channel_id
                                dic_programme["channel_name"] = channel_name
                                dic_programme["generate_source"] = generate_source
                                dic_programme["programme_start"] = "%s%s" % (download_date.strftime("%Y%m%d"), str(td.next_element).strip().replace(":", ""))
                            elif row == 1:
                                dic_programme["title"] = td.next_element.strip()
                                match_episode_num = re.search("^(.*)[\(|\[\|<](\d+[회|강])[\)|\]\|>]$", dic_programme["title"])
                                if match_episode_num:
                                    dic_programme["episode_num"] = match_episode_num.group(2)
                                match_rating = re.search(".*txtcon_grade_pg(\d+)\.gif.*", str(td.img), re.MULTILINE | re.DOTALL)
                                if match_rating:
                                    dic_programme["rating"] = match_rating.group(1)
                            elif row == 2:
                                dic_programme["category"] = str(td.next_element).strip()
                            row += 1
                else:
                    for programme in body.split("<tr>"):
                        match = re.search(".*<td>(\d+):(\d+)<\/td>.*<td class=\"title\">([^\n]*).*<\/td>(.*)<td>\W*(\w*)\W*<\/td>.*<\/tr>", programme, re.MULTILINE | re.DOTALL)
                        if match:
                            if dic_programme:
                                dic_programme["programme_stop"] = "%s%s%s" % (download_date.strftime("%Y%m%d"), match.group(1), match.group(2))
                                generateXmlProgramme(dic_programme)

                            dic_programme.clear()
                            dic_programme["channel_id"] = channel_id
                            dic_programme["channel_name"] = channel_name
                            dic_programme["generate_source"] = generate_source
                            dic_programme["programme_start"] = "%s%s%s" % (download_date.strftime("%Y%m%d"), match.group(1), match.group(2))
                            dic_programme["title"] = match.group(3).rstrip()
                            match_episode_num = re.search("^.*[\(|\[\|<](\d+[회|강])[\)|\]\|>]$", match.group(3).rstrip())
                            if match_episode_num:
                                dic_programme["episode_num"] = match_episode_num.group(1)
                            dic_programme["category"] = match.group(5)
                            match_rating = re.search(".*txtcon_grade_pg(\d+)\.gif.*", match.group(4), re.MULTILINE | re.DOTALL)
                            if match_rating:
                                dic_programme["rating"] = match_rating.group(1)

            progress += 1
            progressLog(progress, len(channel_config) * retrieve_days)

    printLog("===> Done.", end = "\n\n")

def generateXmlProgrammeNaver():
    channel_config = [[k, v] for k, v in channel_list if v[0] == "N"]
    if len(channel_config) <= 0:
        return

    generate_source = "http://www.naver.co.kr/"
    base_url = "http://tvguide.naver.com/program/multiChannel.nhn?broadcastType={broadcast_type}&channelGroup={channel_group}&date={date_ymd}"

    printLog("===> Generate Programmes (Naver)")
    progress = 0
    progressLog(0, len(channel_config) * retrieve_days)

    download_list = []
    for channel in channel_config:
        broadcast_type = channel[1].split(",")[1]
        channel_group = channel[1].split(",")[2]
        if [broadcast_type, channel_group] not in download_list:
            download_list.append([broadcast_type, channel_group])

    for download in download_list:
        broadcast_type = download[0]
        channel_group = download[1]
        download_channel_list = [[k.split(",")[0], k.split(",")[1], v.split(",")[3]] for k, v in channel_config if v.split(",")[1] == broadcast_type and v.split(",")[2] == channel_group]
        for day in range(retrieve_days):
            download_date = (datetime.date.today() + datetime.timedelta(days = day))
            url = base_url.replace("{broadcast_type}", broadcast_type).replace("{channel_group}", channel_group).replace("{date_ymd}", download_date.strftime("%Y%m%d"))

            with urllib.request.urlopen(url) as f:
                html = f.read().decode("utf-8")
                match = re.search("var PROGRAM_SCHEDULES=([^;]+});", html, re.MULTILINE)
                if match:
                    js = json.loads(match.group(1))
                else:
                    js = json.loads(html.text.partition("PROGRAM_SCHEDULES=")[2].rpartition("};")[0]+"}")
                for js_channel in js["channelList"]:
                    group_channel = [[k[0], k[1]] for k in download_channel_list if k[2] == str(js_channel["channelId"])]
                    if group_channel:
                        for programme_channel in group_channel:
                            channel_id = programme_channel[0]
                            channel_name = programme_channel[1]

                            for js_program in js_channel["programList"]:
                                dic_programme = {}
                                dic_programme["channel_id"] = channel_id
                                dic_programme["channel_name"] = channel_name
                                dic_programme["generate_source"] = generate_source
                                dic_programme["programme_start"] = js_program["beginDate"].replace("-","") + js_program["beginTime"].replace(":", "")
                                if int(js_program["beginTime"].replace(":", "")) > int(js_program["endTime"].replace(":", "")):
                                    dic_programme["programme_stop"] = (datetime.datetime.strptime(js_program["beginDate"], "%Y-%m-%d") + datetime.timedelta(days = 1)).strftime("%Y%m%d") + js_program["endTime"].replace(":", "")
                                else:
                                    dic_programme["programme_stop"] = js_program["beginDate"].replace("-","") + js_program["endTime"].replace(":", "")
                                if js_program["subtitle"] != "":
                                    if js_program["episodeNo"] != "":
                                        dic_programme["title"] = "%s <%s> (%s)" % (js_program["scheduleName"], js_program["subtitle"], js_program["episodeNo"])
                                        dic_programme["episode_num"] = js_program["episodeNo"]
                                    else:
                                        dic_programme["title"] = "%s <%s>" % (js_program["scheduleName"], js_program["subtitle"])
                                else:
                                    if js_program["episodeNo"] != "":
                                        dic_programme["title"] = "%s (%s)" % (js_program["scheduleName"], js_program["episodeNo"])
                                        dic_programme["episode_num"] = js_program["episodeNo"]
                                    else:
                                        dic_programme["title"] = js_program["scheduleName"]
                                dic_programme["sub_title"] = dic_programme["title"]
                                dic_programme["desc"] = dic_programme["title"]
                                dic_programme["category"] = js_program["largeGenreId"]
                                if js_program["ageRating"] != 0:
                                    dic_programme["rating"] = str(js_program["ageRating"])

                                generateXmlProgramme(dic_programme)

                        progress += 1
                        progressLog(progress, len(channel_config) * retrieve_days)
    printLog("===> Done.", end = "\n\n")

def generateXmlProgrammeEpg():
    channel_config = [[k, v] for k, v in channel_list if v[0] == "E"]
    if len(channel_config) <= 0:
        return

    generate_source = "http://www.epg.co.kr/"
    base_url = "http://epg.co.kr/php/guide/schedule_day_on.php?search_top_channel_group={top_channel_group}&old_top_channel_group={top_channel_group}&search_sub_channel_group={sub_channel_group}&old_sub_channel_group={sub_channel_group}&ymd={date_y-m-d}&{checkchannel}"
    base_url_epg_checkchannel = "checkchannel%5B{channel_code}%5D={channel_id}"

    printLog("===> Generate Programmes (EPG)")
    progress = 0
    progressLog(0, len(channel_config) * retrieve_days)

    download_list = []
    for channel in channel_config:
        top_channel_group = channel[1].split(",")[1]
        sub_channel_group = channel[1].split(",")[2]
        if [top_channel_group, sub_channel_group] not in download_list:
            download_list.append([top_channel_group, sub_channel_group])

    for download in download_list:
        top_channel_group = download[0]
        sub_channel_group = download[1]
        group_channel = [[k, v] for k, v in channel_config if v.split(",")[1] == top_channel_group and v.split(",")[2] == sub_channel_group]
        checkchannel = ""
        checkchannel_count = 0
        for channel in group_channel:
            channel_id = channel[0].split(",")[0]
            channel_name = channel[0].split(",")[1]
            channel_code = channel[1].split(",")[3]
            checkchannel = checkchannel + "&" + base_url_epg_checkchannel.replace("{channel_code}", channel_code).replace("{channel_id}", channel_id)
            checkchannel_count += 1
            if (checkchannel_count) % 5 == 0 or checkchannel_count == len(group_channel):
                for day in range(retrieve_days):
                    download_date = (datetime.date.today() + datetime.timedelta(days = day))
                    url = base_url.replace("{top_channel_group}", top_channel_group).replace("{sub_channel_group}", sub_channel_group).replace("{checkchannel}", checkchannel).replace("{date_y-m-d}", download_date.strftime("%Y-%m-%d"))

                    with urllib.request.urlopen(url) as f:
                        match_preview = re.findall("(<td>.*Preview\(.*\).*</td>)", f.read().decode("cp949", "ignore").replace("<td>", "\n<td>").replace("</tr>", "\n</tr>"))
                        for preview in match_preview:
                            match_program = re.match(r".*Preview\('[^']*','([^']*)','([^']*)','(\d*/\d* [^<]*)<br>~(\d*/\d* [^']*)','([^']*)','[^']*','[^']*'\).*", preview)
                            if match_program:
                                programme_channel_list = [k for k, v in group_channel if k.split(",")[0] == match_program.group(2)]
                                for programme_channel in programme_channel_list:
                                    dic_programme = {}
                                    dic_programme["channel_id"] = programme_channel.split(",")[0]
                                    dic_programme["channel_name"] = programme_channel.split(",")[1]
                                    dic_programme["generate_source"] = generate_source
                                    dic_programme["title"] = html.unescape(match_program.group(1))
                                    match_episode_num = re.search("^.*[\(|\[](\d+[회|강])[\)|\]]$", dic_programme["title"])
                                    if match_episode_num:
                                        dic_programme["episode_num"] = match_episode_num.group(1)
                                    match_rating = re.search(".*schedule_(\d+)\.gif.*", preview)
                                    if match_rating:
                                        dic_programme["rating"] = match_rating.group(1)
                                    start_date = datetime.datetime.strptime("%d %s" % (download_date.year, match_program.group(3)), "%Y %m/%d %p %I:%M")
                                    if download_date.month == 12 and start_date.month == 1:
                                        start_date = start_date + datetime.timedelta(year = 1)
                                    dic_programme["programme_start"] = start_date.strftime("%Y%m%d%H%M")
                                    end_date = datetime.datetime.strptime("%d %s" % (download_date.year, match_program.group(4)), "%Y %m/%d %p %I:%M")
                                    if download_date.month == 12 and end_date.month == 1:
                                        end_date = end_date + datetime.timedelta(year = 1)
                                    dic_programme["programme_stop"] = end_date.strftime("%Y%m%d%H%M")
                                    end = match_program.group(4)
                                    dic_programme["category"] = match_program.group(5).split("-")[0]

                                    generateXmlProgramme(dic_programme)

                        progress += checkchannel_count
                        progressLog(progress, len(channel_config) * retrieve_days)

                checkchannel = ""
                checkchannel_count = 0
    printLog("===> Done.", end = "\n\n")

def getCategory(category):
    if category == "드라마":
        category_ko = category
        category_en = "Movie / Drama"
    elif category == "영화":
        category_ko = category
        category_en = "Movie / Drama"
    elif category == "만화":
        category_ko = category
        category_en = "Children's / Youth programmes"
    elif category == "연예/오락":
        category_ko = category
        category_en = "Show / Games"
    elif category == "스포츠":
        category_ko = category
        category_en = "Sports"
    elif category == "라이프":
        category_ko = category
        category_en = "Leisure hobbies"
    elif category == "공연/음악":
        category_ko = category
        category_en = "Music / Ballet / Dance"
    elif category == "교육":
        category_ko = category
        category_en = "Education / Science / Factual topics"
    elif category == "뉴스/정보":
        category_ko = category
        category_en = "News / Current affairs"
    elif category == "다큐":
        category_ko = category
        category_en = "Social / Political issues / Economics"
    elif category == "예술":
        category_ko = category
        category_en = "Arts / Culture (without music)"
    elif category == "A":
        category_ko = "드라마"
        category_en = "Movie / Drama"
    elif category == "B":
        category_ko = "영화"
        category_en = "Movie / Drama"
    elif category == "C":
        category_ko = "만화"
        category_en = "Children's / Youth programmes"
    elif category == "D":
        category_ko = "연예/오락"
        category_en = "Show / Games"
    elif category == "E":
        category_ko = "스포츠"
        category_en = "Sports"
    elif category == "F":
        category_ko = "취미/레저"
        category_en = "Leisure hobbies"
    elif category == "G":
        category_ko = "음악"
        category_en = "Music / Ballet / Dance"
    elif category == "H":
        category_ko = "교육"
        category_en = "Education / Science / Factual topics"
    elif category == "I":
        category_ko = "뉴스"
        category_en = "News / Current affairs"
    elif category == "J":
        category_ko = "시사/다큐"
        category_en = "Social / Political issues / Economics"
    elif category == "K":
        category_ko = "교양/정보"
        category_en = "Arts / Culture (without music)"
    elif category == "L":
        category_ko = "홈쇼핑"
        category_en = ""
    elif category == "시사/다큐":
        category_ko = category
        category_en = "Social / Political issues / Economics"
    elif category == "교양/정보":
        category_ko = category
        category_en = "Arts / Culture (without music)"
    elif category == "홈쇼핑":
        category_ko = category
        category_en = ""
    else:
        category_ko = ""
        category_en = ""

    return category_ko, category_en

def postProc():
    if post_proc and os.path.exists(post_proc):
        match_post_proc = re.match("^\w.*$", post_proc)
        if match_post_proc:
            call(["./%s" % post_proc, post_proc_args])
        else:
            call([post_proc, post_proc_args])

def generateChannelListUplus(o):
    printLog("===> Generate Channel List (Uplus)")
    total = 0
    printLog("##LG유플러스", file = o)
    printLog("#http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvSchedule.hpi?chnlCd={channelId}&evntCmpYmd=YYYYMMDD", file = o)
    printLog("#channelId,channelName", file = o)
    with urllib.request.urlopen("http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvContentsMFamily.hpi") as f:
        html = f.read().decode("cp949", "ignore")
        if __USE_LXML:
            soup = BeautifulSoup(html, "lxml")
        else:
            soup = BeautifulSoup(html, "html.parser")
        for a in soup.select('a[href]'):
            if a['href'] == '#CHANNEL':
                printLog("#LG유플러스 %s" % a.text, file = o)
                match = re.match(".*\('(.*)','(.*)','.*'\).*", a['onclick'])
                if match:
                    with urllib.request.urlopen("http://www.uplus.co.kr/css/chgi/chgi/RetrieveTvChannel.hpi?code=%s&category=%s" % (match.group(2), match.group(1))) as f2:
                        html2 = f2.read().decode("cp949", "ignore")
                        if __USE_LXML:
                            soup2 = BeautifulSoup(html2, "lxml")
                        else:
                            soup2 = BeautifulSoup(html2, "html.parser")
                        for b in soup2.select('a[href]'):
                            if b['href'] == '#':
                                match2 = re.match(".*retrieveSchedule\('(.*)','.*'\).*", b['onclick'])
                                if match2:
                                    printLog("U,%s,%s" % (match2.group(1), b.text), file = o)
                                    total += 1
                                    progressCount(total)
    printLog("", file = o)
    printLog("")
    printLog("===> Done.", end = "\n\n")
                                    
def generateChannelListNaver(o):
    printLog("===> Generate Channel List (Naver)")
    total = 0
    printLog("##네이버", file = o)
    printLog("#http://tvguide.naver.com/program/multiChannel.nhn?broadcastType={broadcastType}&channelGroup={channelGroup}&date=YYYYMMDD", file = o)
    printLog("#broadcastType,channelGroup,channelId,channelName", file = o)
    with urllib.request.urlopen("http://tvguide.naver.com/program/multiChannel.nhn") as f:
        html = f.read().decode("utf-8", "ignore")
        if __USE_LXML:
            soup = BeautifulSoup(html, "lxml")
        else:
            soup = BeautifulSoup(html, "html.parser")
        i = 0
        for a in soup.select('div[class=channel_area] a[href]'):
            if a['href'] == "#":
                continue
            if 'myChannel' in a['href']:
                continue
            with urllib.request.urlopen("http://tvguide.naver.com" + a['href']) as f2:
                html2 = f2.read().decode("utf-8", "ignore")
                if __USE_LXML:
                    soup2 = BeautifulSoup(html2, "lxml")
                else:
                    soup2 = BeautifulSoup(html2, "html.parser")

                #지상파
                layer_areaset = soup2.select('div[class=layer_areaset] a[href]')
                for layer_area in layer_areaset:
                    if layer_area['href'] == "#":
                        continue
                    printLog("#네이버 %s (%s)" % (a.text, layer_area.text), file = o)
                    match_layer_area = re.match(".*broadcastType=(\d+)\&channelGroup=(\d+)\&.*", layer_area['href'])
                    if match_layer_area:
                        broadcastType = match_layer_area.group(1)
                        channelGroup = match_layer_area.group(2)
                        with urllib.request.urlopen("http://tvguide.naver.com" + layer_area['href']) as f3:
                            html3 = f3.read().decode('utf-8')
                            match = re.search("var PROGRAM_SCHEDULES=([^;]+});", html3, re.MULTILINE)
                            if match:
                                js = json.loads(match.group(1))
                            else:
                                js = json.loads(html.text.partition("PROGRAM_SCHEDULES=")[2].rpartition("};")[0]+"}")
                            for js_channel in js["channelList"]:
                                printLog("N,%s,%s,%s,%s" % (broadcastType, channelGroup, js_channel["channelId"], js_channel["channelName"]), file = o)
                                total += 1
                                progressCount(total)

                #케이블/스카이라이프
                cable_list = [k for k in soup2.select('ul[class]') if k['class'][0] == "cable_list"]
                for c in cable_list:
                    for d in c.select("a[href]"):
                        printLog("#네이버 %s (%s)" % (a.text, d.text), file = o)
                        match_cable_list = re.match(".*broadcastType=(\d+)\&channelGroup=(\d+)\&.*", d['href'])
                        if match_cable_list:
                            broadcastType = match_cable_list.group(1)
                            channelGroup = match_cable_list.group(2)
                            with urllib.request.urlopen("http://tvguide.naver.com" + d['href']) as f3:
                                html3 = f3.read().decode('utf-8')
                                match = re.search("var PROGRAM_SCHEDULES=([^;]+});", html3, re.MULTILINE)
                                if match:
                                    js = json.loads(match.group(1))
                                else:
                                    js = json.loads(html.text.partition("PROGRAM_SCHEDULES=")[2].rpartition("};")[0]+"}")
                                for js_channel in js["channelList"]:
                                    printLog("N,%s,%s,%s,%s" % (broadcastType, channelGroup, js_channel["channelId"], js_channel["channelName"]), file = o)
                                    total += 1
                                    progressCount(total)

                #케이블/스카이라이프 추가
                s_more_wrap = [k for k in soup2.select('ul[id=s_more_lst_ul]')]
                for c in s_more_wrap:
                    for d in c.select("a[href]"):
                        printLog("#네이버 %s (%s)" % (a.text, d.text), file = o)
                        match_cable_list = re.match(".*broadcastType=(\d+)\&channelGroup=(\d+)\&.*", d['href'])
                        if match_cable_list:
                            broadcastType = match_cable_list.group(1)
                            channelGroup = match_cable_list.group(2)
                            with urllib.request.urlopen("http://tvguide.naver.com" + d['href']) as f3:
                                html3 = f3.read().decode('utf-8')
                                match = re.search("var PROGRAM_SCHEDULES=([^;]+});", html3, re.MULTILINE)
                                if match:
                                    js = json.loads(match.group(1))
                                else:
                                    js = json.loads(html.text.partition("PROGRAM_SCHEDULES=")[2].rpartition("};")[0]+"}")
                                for js_channel in js["channelList"]:
                                    printLog("N,%s,%s,%s,%s" % (broadcastType, channelGroup, js_channel["channelId"], js_channel["channelName"]), file = o)
                                    total += 1
                                    progressCount(total)

                #종합편성/해외위성
                if not layer_areaset and not cable_list and not s_more_wrap:
                    printLog("#네이버 %s" % a.text, file = o)
                    match1 = re.match(".*broadcastType=(\d+)\&.*", a['href'])
                    match2 = re.match(".*channelGroup=(\d+)\&.*", a['href'])
                    if match1:
                        broadcastType = match1.group(1)
                    else:
                        broadcastType = ""
                    if match2:
                        channelGroup = match2.group(1)
                    else:
                        channelGroup = ""

                    if match1:
                        match = re.search("var PROGRAM_SCHEDULES=([^;]+});", html2, re.MULTILINE)
                        if match:
                            js = json.loads(match.group(1))
                        else:
                            js = json.loads(html.text.partition("PROGRAM_SCHEDULES=")[2].rpartition("};")[0]+"}")
                        for js_channel in js["channelList"]:
                            printLog("N,%s,%s,%s,%s" % (broadcastType, channelGroup, js_channel["channelId"], js_channel["channelName"]), file = o)
                            total += 1
                            progressCount(total)
    printLog("", file = o)
    printLog("")
    printLog("===> Done.", end = "\n\n")

def generateChannelListEpg(o):
    printLog("===> Generate Channel List (EPG)")
    total = 0
    printLog("##EPG", file = o)
    printLog("#http://www.epg.co.kr/new/tvguide/tvguide.php?search_top_channel_group={search_top_channel_group}&old_top_channel_group={search_top_channel_group}&search_sub_channel_group={search_sub_channel_group}&old_sub_channel_group={search_sub_channel_group}&ymd={date}&{channel}", file = o)
    printLog("#top_channel_group,sub_channel_group,checkchannel,channel_name", file = o)
    with urllib.request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php") as f:
        html = f.read().decode("cp949", "ignore")
        soup = BeautifulSoup(html, "lxml")
        for a in soup.select('select[name=search_top_channel_group] option'):
            if 'selected' in a.attrs:
                top_channel_group = ""
                sub_channel_group = ""
                printLog("#EPG %s" % a.text, file = o)
                for b in soup.select('input[name=search_top_channel_group]'):
                    if 'value' in b.attrs:
                        top_channel_group = b['value']
                        break
                for b in soup.select('input[name=search_sub_channel_group]'):
                    if 'value' in b.attrs:
                        sub_channel_group = b['value']
                        break
                for b in soup.select('input[name^=checkchannel]'):
                    if b['type'] == "checkbox":
                        printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, b['name'].replace('checkchannel[', '').replace(']', ''), b['value']), file = o)
                        total += 1
                        progressCount(total)
            else:
                with urllib.request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php?search_top_channel_group=%s" % a['value']) as f2:
                    html2 = f2.read().decode("cp949", "ignore")
                    soup2 = BeautifulSoup(html2, "lxml")
                    for b in soup2.select('select[name=search_sub_channel_group] option'):
                        if b['value'] == '':
                            continue
                        if 'selected' in b.attrs:
                            top_channel_group = ""
                            sub_channel_group = ""
                            printLog("#EPG %s(%s)" % (a.text, b.text), file = o)
                            for c in soup2.select('input[name=search_top_channel_group]'):
                                if 'value' in c.attrs:
                                    top_channel_group = c['value']
                                    break
                            for c in soup2.select('input[name=search_sub_channel_group]'):
                                if 'value' in c.attrs:
                                    sub_channel_group = c['value']
                                    break
                            for c in soup2.select('input[name^=checkchannel]'):
                                if c['type'] == "checkbox":
                                    printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, c['name'].replace('checkchannel[', '').replace(']', ''), c['value']), file = o)
                                    total += 1
                                    progressCount(total)
                        else:
                            with urllib.request.urlopen("http://epg.co.kr/php/guide/schedule_day_on.php?search_top_channel_group=%s&old_top_channel_group=%s&search_sub_channel_group=%s&old_sub_channel_group=%s" % (a['value'], a['value'], b['value'], b['value'])) as f3:
                                html3 = f3.read().decode("cp949", "ignore")
                                soup3 = BeautifulSoup(html3, "lxml")
                                top_channel_group = a['value']
                                sub_channel_group = b['value']
                                printLog("#EPG %s(%s)" % (a.text, b.text), file = o)
                                for d in soup3.select('input[name^=checkchannel]'):
                                    if d['type'] == "checkbox":
                                        printLog("E,%s,%s,%s,%s" % (top_channel_group, sub_channel_group, d['name'].replace('checkchannel[', '').replace(']', ''), d['value']), file = o)
                                        total += 1
                                        progressCount(total)
    printLog("", file = o)
    printLog("")
    printLog("===> Done.", end = "\n\n")

def generateChannelList():
    with open(LIST_FILE, "r+") as f:
        o = []
        o.append(f)
        if args.v:
            o.append(sys.stderr)

        generateChannelListUplus(o)
        generateChannelListNaver(o)
        generateChannelListEpg(o)

if __name__ == '__main__':
    argumentParser = argparse.ArgumentParser()
    argumentParser.add_argument("-v", "--v", action="store_true", help="verbose")
    argumentParser.add_argument("-b", "--b", action="store_true", help="pretty_print")
    argumentParser.add_argument("-g", "--g", action="store_true", help="generate_list")
    args = argumentParser.parse_args()

    if args.g:
        if not __USE_BS:
            printLog("채널 소스 생성은 BeautifulSoup4가 필요합니다.")
            exit(1)
        generateChannelList()

    else:
        readConfig()

        generateXmlRoot()

        generateXmlChannel()

        generateXmlProgrammeUplus()

        generateXmlProgrammeNaver()

        generateXmlProgrammeEpg()

        writeXml()
        postProc()

        if args.v:
            printXml()

    printLog("===> Execution time : %.2fs" % (time.time() - ___START_TIME))

